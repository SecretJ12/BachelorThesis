

\section{Termination proof} \label{chapter:termination}

The command $\texttt{define\_time\_fun}$ tries to automatically proof termination of the timing function.
Therefore it uses two different tactics.
Just as the name of the command suggests the first try is equivalent to the command $\texttt{fun}$.
Both use the tactic $\texttt{lexicographic\_order}$ in order to proof termination.
We now look at the following function $\texttt{sum}$, where this tactic fails.
\begin{lstlisting}[language=isabelle,mathescape=true]
  function sum :: "nat => nat => nat" where
    "sum i j = (if j $\le$ i then 0 else i + sum (Suc i) j)"
    by pat_completeness auto
  termination
    by (relation "measure ($\lambda$(i,j). j - i)") auto
\end{lstlisting}

Termination needs to be proved manually, therefore the first tactic also fails for the timing function.
But as we have already proved termination for this function, we can make use of it for the running time function.
The second strategy does this and tries to cover all functions.
In the first step we register the timing function equivalent to using the $\texttt{function}$ command.
\begin{lstlisting}[language=isabelle,mathescape=true,caption=Function registration,label=lst:sum_reg]
  function (domintros) T_sum :: "nat => nat => nat" where
    "T_sum i j = 1 + (if j $\le$ i then 0 else T_sum (Suc i) j)"
    by pat_completeness auto
\end{lstlisting}
In Isabelle every function needs to terminate.
Before this the simp rules are not usable.
However we receive another function called $T\_sum\_dom$.
It represents the domain of arguments in which $T\_sum$ terminates.
Therefore it takes the arguments of $T\_sum$ as a tuple and yields $True$ if the function terminates for them and $False$ otherwise.
Based on this the rules psimps are generated.
They state the following: Under the assumption of $T\_sum$ terminating the corresponding simp rule holds.

\begin{figure}[H]
\begin{align*}
  &\texttt{T\_sum\_dom (?i, ?j)}\\
  &\texttt{$\Longrightarrow$ T\_sum ?i ?j = 1 + (if ?j $\le$ ?i then 0 else T\_sum (Suc ?i) ?j)}
\end{align*}
\caption{T\_sum.psimps}
\end{figure}

From this equation we can see how the termination proof works.
In order to obtain the simp rules we need to show, that $T\_sum\_dom$ holds for every argument.
Before we start with the proof, we need to look at another another set of generated rules.
The $\texttt{domintros}$ rules state when a function call terminates.
This happens if all the recursive calls made also terminate.
Those rules are not generated by default due to performance resasons, we needed to explicitely pass the option domintros to obtain them.
This already happend in the listing \ref{lst:sum_reg}.
For our sum function the domintros rule has the following form shown in figure \ref{fig:domintros}.
From this we can see, that a function call with the variables $\texttt{i}$ and $\texttt{j}$ with $\texttt{j > i}$ terminates,
if the function call with $\texttt{Suc i}$ and $\texttt{j}$ terminates.
\begin{figure}[H]
\begin{align*}
  \texttt{($\lnot$ ?j $\le$ ?i $\Longrightarrow$ T\_sum\_dom (Suc ?i, ?j)) $\Longrightarrow$ T\_sum\_dom (?i, ?j)}
\end{align*}
\caption{T\_sum.domintros}
\label{fig:domintros}
\end{figure}

This gives us all the needed rules to prove our goal.
We start by setting up the goal of the form ``$\texttt{T\_f\_dom (a}_{1}\texttt{,}\dots\texttt{,a}_{n}\texttt{)}$''.
On this goal we perform an induction with the induction schema provided by the original function.
This is already the step where we use the termination proof of the original function,
as the induction schema is proved through the termination.
To argue about the next step we need to look at the translation schema for out timing functions.
Taking the if-else construct as an example, the place where recursive function calls are made don't change.
All function calls inside the condition will still be executed without another precondition.
For the function calls inside the then and else branch the preconditions stay the same, as the condition is evaluated as in the original function.
This justifies why the resulting cases stay close to the original function.
Taking the sum function as an example the following goal is generated after applying induction.
\begin{align*}
  \texttt{$\bigwedge$i j. ($\lnot$ j $\le$ i $\Longrightarrow$ T\_sum\_dom (Suc i, j)) $\Longrightarrow$ T\_sum\_dom (i,j)}
\end{align*}
As expected it looks similar to the domintros rule shown in listing \ref{lst:domintros}.
With its help we are also able to solve the goal.
In order to support as many cases as possible we use metis as advanced prover for it.
With the just proven goal the auto tactic is now able to prove termination.
The whole proof can be found in listing \ref{lst:proof_schema}.
\begin{lstlisting}[language=isabelle,mathescape=true,label=lst:proof_schema,caption=Proof schema over dom with help of original function]
  lemma T_sum_dom: "T_sum_dom (i,j)"
    apply (induction i j rule: sum.induct)
    apply (metis T_sum.domintros)
    done
  termination
    by (auto simp: T_sum_dom)
\end{lstlisting}

Internally auto is used before metis, as it can do some more simplifications and therefore cover more edgecases.
For functions with multiple equations, the induction schema will create multiple goals.
The automation first tries to solve every goal by the corresponding domintros rule and falls back to all domintros rules in case of failure.
This behaviour reduces the number of ``Unused theorems'' warnings.
The named lemma in listing \ref{lst:proof_schema} is just for demonstration purposes.
The converter works with only internally usable goals.
