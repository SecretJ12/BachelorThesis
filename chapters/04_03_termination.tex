

\section{Termination proof} \label{chapter:termination}

The command $\texttt{define\_time\_fun}$ tries to automatically prove termination of the timing function.
Therefore, it uses two different tactics.
The first try equals the command $\texttt{fun}$ as the command name suggests.
Both use the tactic $\texttt{lexicographic\_order}$ in order to prove termination.
We now look at the following function $\texttt{sum}$, where this tactic fails.
\begin{lstlisting}[language=isabelle,mathescape=true]
  function sum :: "nat => nat => nat" where
    "sum i j = (if j $\le$ i then 0 else i + sum (Suc i) j)"
    by pat_completeness auto
  termination
    by (relation "measure ($\lambda$(i,j). j - i)") auto
\end{lstlisting}

Termination needs to be proved manually.
Therefore, the first tactic also fails for the timing function.
However, as we have already proved termination for this function, we can use it for the running time function.
The second strategy does this and tries to cover all functions.
In the first step, we register the timing function equivalent to using the $\texttt{function}$ command.
\begin{lstlisting}[language=isabelle,mathescape=true,caption=Function registration,label=lst:sum_reg]
  function (domintros) T_sum :: "nat => nat => nat" where
    "T_sum i j = 1 + (if j $\le$ i then 0 else T_sum (Suc i) j)"
    by pat_completeness auto
\end{lstlisting}
In Isabelle, every function needs to terminate.
Before this, the simp rules are not usable.
However, we receive another function called $T\_sum\_dom$.
It represents the domain of arguments in which $T\_sum$ terminates.
Therefore, it takes the arguments of $T\_sum$ as a tuple and yields $True$ if the function terminates for them and $False$ otherwise.
Based on this, the rules psimps are generated.
They state the following: Under the assumption of $T\_sum$ terminating, the corresponding simp rule holds.
The psimps rule for $T\_sum$ is given in (\ref{eq:T_sum.psimps}).

\begin{equation}
  \begin{aligned}
  &\texttt{T\_sum\_dom (?i, ?j)}\\
  &\texttt{$\Longrightarrow$ T\_sum ?i ?j = 1 + (if ?j $\le$ ?i then 0 else T\_sum (Suc ?i) ?j)}
  \end{aligned}
  \label{eq:T_sum.psimps}
\end{equation}

From this equation, we can see how the termination proof works.
In order to obtain the simp rules, we need to show that $T\_sum\_dom$ holds for every argument.
Before we start with the proof, we need to look at another set of generated rules.
The $\texttt{domintros}$ rules state when a function call terminates.
Termination happens if all the recursive calls made also terminate.
Those rules are not generated by default due to performance reasons.
We needed to explicitly pass the option domintros to obtain them.
This already happened in \autoref{lst:sum_reg}.
For our sum function, the domintros rule has the following form shown in (\ref{eq:domintros}).
From this, we can see that a function call with the variables $\texttt{i}$ and $\texttt{j}$ with $\texttt{j > i}$ terminates
if the function call with $\texttt{Suc i}$ and $\texttt{j}$ terminates.
\begin{equation}
  \texttt{($\lnot$ ?j $\le$ ?i $\Longrightarrow$ T\_sum\_dom (Suc ?i, ?j)) $\Longrightarrow$ T\_sum\_dom (?i, ?j)}
\label{eq:domintros}
\end{equation}

This gives us all the rules we need to prove our goal.
We start by setting up the goal of the form ``$\texttt{T\_f\_dom (a}_{1}\texttt{,}\dots\texttt{,a}_{n}\texttt{)}$''.
On this goal we perform an induction with the induction schema provided by the original function.
This is already the step where we use the termination proof of the original function,
as the induction schema is proved through the termination.
To argue about the next step, we need to look at the translation schema for our timing functions.
Taking the if-else construct as an example, the place where recursive function calls are made does not change.
All function calls inside the condition will still be executed without another precondition.
For the function calls inside the then and else branches, the preconditions stay the same, as the condition is evaluated as in the original function.
This justifies why the resulting cases stay close to the original function.
Taking the sum function as an example, the induction creates the goal
\begin{equation*}
  \texttt{$\bigwedge$i j. ($\lnot$ j $\le$ i $\Longrightarrow$ T\_sum\_dom (Suc i, j)) $\Longrightarrow$ T\_sum\_dom (i,j)}.
\end{equation*}
As expected, it is similar to the domintros rule shown in (\ref{eq:domintros}).
With its help, we are also able to solve the goal.
In order to support as many cases as possible, we use metis as an advanced prover.
With the just-proven goal, the auto tactic can now prove termination.
The whole proof can be found in \autoref{lst:proof_schema}.
\begin{lstlisting}[language=isabelle,mathescape=true,label=lst:proof_schema,caption=Proof schema over dom with help of original function]
  lemma T_sum_dom: "T_sum_dom (i,j)"
    apply (induction i j rule: sum.induct)
    apply (metis T_sum.domintros)
    done
  termination
    by (auto simp: T_sum_dom)
\end{lstlisting}

Internally, auto is used before metis, as it can do some more simplifications and, therefore, cover more edgecases.
For functions with multiple equations, the induction schema will create multiple goals.
The automation first tries to solve every goal by the corresponding domintros rule and falls back to all domintros rules in case of failure.
This behavior reduces the number of ``Unused theorems'' warnings.
The named lemma in \autoref{lst:proof_schema} is just for demonstration purposes.
The converter works with only internally usable goals.
